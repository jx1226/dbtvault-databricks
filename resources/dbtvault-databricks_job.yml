resources:
  jobs:
    dbtvault-databricks_job:
      name: dbtvault-databricks_job

      schedule:
        # Run every day at 9:27 AM
        quartz_cron_expression: 21 27 9 * * ?
        timezone_id: UTC

      email_notifications:
        on_failure:
          - jie.xin@avanade.com

      tasks:
        - task_key: dbt

          dbt_task:
            project_directory: ../
            # The default schema, catalog, etc. are defined in ../dbt_profiles/profiles.yml
            profiles_directory: dbt_profiles/
            commands:
            - 'dbt deps --target=${bundle.target}'
            - 'dbt seed --target=${bundle.target} --vars "{ dev_schema: {{$dev_schema}} }"'
            - 'dbt run --target=${bundle.target} --vars "{ dev_schema: {{$dev_schema}} }"'

          libraries:
          - pypi:
              package: dbt-databricks>=1.0.0,<2.0.0

          new_cluster:
            spark_version: 13.3.x-scala2.12
            spark_conf:
              spark.master: local[*, 4]
              spark.databricks.cluster.profile: singleNode
            azure_attributes:
              first_on_demand: 1
              availability: ON_DEMAND_AZURE
              spot_bid_max_price: -1
            node_type_id: Standard_D4ds_v5
            custom_tags:
              ResourceClass: SingleNode
            spark_env_vars:
              PYSPARK_PYTHON: /databricks/python3/bin/python3
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            runtime_engine: PHOTON
            num_workers: 0
      queue:
        enabled: true